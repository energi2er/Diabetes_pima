{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "\n",
    "data.info()\n",
    "print(\"row one of dataset:\\n\",data.head(1))\n",
    "\n",
    "# Display basic statistics of the dataset\n",
    "print(\"Basic Statistics of the Dataset:\")\n",
    "print(data.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = data.drop(columns=['Outcome'])  # Assuming 'Outcome' is the target variable\n",
    "y = data['Outcome']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  random_state=104,  test_size=0.3,  shuffle=True) \n",
    "\n",
    "# Print out train and test sets\n",
    "print('X_train row zero: ') \n",
    "print(X_train.head(0)) \n",
    "print('') \n",
    "print('X_test row zero: ') \n",
    "print(X_test.head(0)) \n",
    "print('') \n",
    "print('y_train ro w zero: ') \n",
    "print(y_train.head(0)) \n",
    "print('') \n",
    "print('y_test row zero: ') \n",
    "print(y_test.head(0))\n",
    "\n",
    "#there is no null value but there is some zerro value that must considet!\n",
    "#y_train = y_train[X_train.index]  #Adjust y_train accordingly after dropping rows\n",
    "# Count zero values in the 'SkinThickness' column in the training dataset\n",
    "zero_skinthickness_count = (X_train['SkinThickness'] == 0).sum()\n",
    "print(\"\\nNumber of zero values in the 'SkinThickness' column in the training dataset:\", zero_skinthickness_count)\n",
    "\n",
    "# Count zero values in the 'Glucose' column in the training dataset\n",
    "glucose_zeros_count = (X_train['Glucose'] == 0).sum()\n",
    "print(\"Number of zero values in the 'Glucose' column in the training dataset:\", glucose_zeros_count)\n",
    "\n",
    "# Count zero values in the 'BMI' column in the training dataset\n",
    "zero_bmi_count = (X_train['BMI'] == 0).sum()\n",
    "print(\"Number of zero values in the 'BMI' column in the training dataset:\", zero_bmi_count)\n",
    "\n",
    "# the zero value left untouched but it consider in scaling and standardaizing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with X_train and y_train (The pandas. concat() function concatenates and combines multiple DataFrames or Series into a single, unified DataFrame or Series.)\n",
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "# Calculate the mean of each feature for outcome 0 and outcome 1\n",
    "#mean_outcome_0 = train_data[train_data['Outcome'] == 0].mean()\n",
    "#mean_outcome_1 = train_data[train_data['Outcome'] == 1].mean()\n",
    "\n",
    "# Fill missing values for 'BMI', 'Glucose', and 'BloodPressure' based on the mean of each feature for the respective outcome groups\n",
    "#for feature in ['BMI', 'Glucose', 'BloodPressure' , 'SkinThickness','Age']:\n",
    "    # Fill missing values for outcome 0\n",
    " #   X_train.loc[(X_train[feature] == 0) & (y_train == 0), feature] = mean_outcome_0[feature].astype('int64')\n",
    "    # Fill missing values for outcome 1\n",
    " #   X_train.loc[(X_train[feature] == 0) & (y_train == 1), feature] = mean_outcome_1[feature].astype('int64')\n",
    "\n",
    "# Print the updated X_train with filled missing values\n",
    "#print(\"X_train with filled missing values:\")\n",
    "#print(X_train.head(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analyze the distribution of features correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the correlation matrix for X_train\n",
    "correlation_matrix = X_train.corr()\n",
    "\n",
    "# Plot the correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of each feature in X_train\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(X_train.columns):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.histplot(X_train[column], kde=True)\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualize pairwise relationships between features in X_train\n",
    "sns.pairplot(data, hue= 'Outcome' )\n",
    "plt.suptitle(\"Pairwise Relationships between Features\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize boxplots to identify outliers in X_train\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, column in enumerate(X_train.columns):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    sns.boxplot(x=y, y=X_train[column])\n",
    "    plt.title(column)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "#Shaping the dataset according to my requirements. The dataset has already been split into training and test sets before the shaping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X_train is your dataset containing features\n",
    "# Let's say X_train has columns ['BMI', 'Glucose', 'BloodPressure', 'SkinThickness', 'Age']\n",
    "\n",
    "# Create a new DataFrame to store the extended dataset\n",
    "X_train_ex = X_train.copy()\n",
    "X_test_ex  =X_test.copy()\n",
    "data_ex = data.copy()\n",
    "# List of pairs of features to combine\n",
    "feature_pairs = [('BMI', 'Glucose'), ('BMI', 'BloodPressure'), ('BMI', 'SkinThickness'), ('BMI', 'Age'),\n",
    "                 ('Glucose', 'BloodPressure'), ('Glucose', 'SkinThickness'), ('Glucose', 'Age'),\n",
    "                 ('BloodPressure', 'SkinThickness'), ('BloodPressure', 'Age'),\n",
    "                 ('SkinThickness', 'Age')]\n",
    "\n",
    "# Iterate through each pair of features\n",
    "for feat1, feat2 in feature_pairs:\n",
    "    # Create new feature by combining the values of two existing features\n",
    "    new_feature_name = feat1 + 'Plus' + feat2\n",
    "    X_train_ex[new_feature_name] = X_train_ex[feat1] + X_train_ex[feat2]\n",
    "    X_test_ex[new_feature_name] = X_test_ex[feat1] + X_test_ex[feat2]\n",
    "    data_ex[new_feature_name]= data_ex[feat1] + data_ex[feat2]\n",
    "\n",
    "# Now X_train_ex contains the original features plus the new features created by combining pairs of existing features\n",
    "print(data_ex.head(1))\n",
    "\n",
    "# Visualize pairwise relationships between features in X_train\n",
    "sns.pairplot(data_ex, hue= 'Outcome' )\n",
    "plt.suptitle(\"Pairwise Relationships between Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    " #Selecting specific features\n",
    "selected_features = ['BMI', 'Age', 'Glucose', 'BloodPressure','DiabetesPedigreeFunction']\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# Train Support Vector Machine (SVM) model\n",
    "svm_model = SVC(C= 10000, kernel= 'poly',gamma='scale')\n",
    "svm_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, max_depth=100,criterion= 'entropy',\n",
    "        min_samples_split=6, random_state=42, bootstrap= True,\n",
    "        max_features=4\n",
    "        )\n",
    "rf_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Train Logistic Regression model with increased max_iter\n",
    "lr_model = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "lr_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_test_pred = svm_model.predict(X_test_selected)\n",
    "rf_test_pred = rf_model.predict(X_test_selected)\n",
    "lr_test_pred = lr_model.predict(X_test_selected)\n",
    "\n",
    "# Evaluate the models on the test set\n",
    "svm_test_accuracy = accuracy_score(y_test, svm_test_pred)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_pred)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_pred)\n",
    "\n",
    "print(\"Test Set Accuracy:\")\n",
    "print(\"Support Vector Machine (SVM) Accuracy:\", svm_test_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_test_accuracy)\n",
    "print(\"Logistic Regression Accuracy:\", lr_test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Evaluate the models on the test set\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"Support Vector Machine (SVM):\")\n",
    "print(classification_report(y_test, svm_test_pred))\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, rf_test_pred))\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, lr_test_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Support Vector Machine (SVM) model\n",
    "selected_features_ex = ['BMIPlusGlucose','GlucosePlusSkinThickness','GlucosePlusAge','BMIPlusBloodPressure','BMIPlusAge']\n",
    "X_train_ex_selected = X_train_ex[selected_features_ex]\n",
    "X_test_ex_selected = X_test_ex[selected_features_ex]\n",
    "\n",
    "# Train Support Vector Machine (SVM) model\n",
    "svm_model = SVC(C= 10, kernel= 'rbf',gamma='scale')\n",
    "svm_model.fit(X_train_ex_selected, y_train)\n",
    "\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=1000, max_depth=100, criterion='entropy',\n",
    "                                  min_samples_split=2, random_state=42, bootstrap=True,\n",
    "                                  max_features=32)\n",
    "rf_model.fit(X_train_ex_selected, y_train)\n",
    "\n",
    "# Train Logistic Regression model with increased max_iter\n",
    "lr_model = LogisticRegression(max_iter=10000, solver='lbfgs')\n",
    "lr_model.fit(X_train_ex_selected, y_train)\n",
    "# Test Support Vector Machine (SVM) model\n",
    "svm_test_pred = svm_model.predict(X_test_ex_selected )\n",
    "\n",
    "# Test Random Forest model\n",
    "rf_test_pred = rf_model.predict(X_test_ex_selected )\n",
    "\n",
    "# Test Logistic Regression model\n",
    "lr_test_pred = lr_model.predict(X_test_ex_selected )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Compute accuracy score for each model\n",
    "svm_test_accuracy = accuracy_score(y_test, svm_test_pred)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_pred)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_pred)\n",
    "\n",
    "print(\"Test Set Accuracy:\")\n",
    "print(\"Support Vector Machine (SVM) Accuracy:\", svm_test_accuracy)\n",
    "print(\"Random Forest Accuracy:\", rf_test_accuracy)\n",
    "print(\"Logistic Regression Accuracy:\", lr_test_accuracy)\n",
    "\n",
    "# Evaluate the models on the test set\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"Support Vector Machine (SVM):\")\n",
    "print(classification_report(y_test, svm_test_pred))\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(classification_report(y_test, rf_test_pred))\n",
    "\n",
    "print(\"Logistic Regression:\")\n",
    "print(classification_report(y_test, lr_test_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
